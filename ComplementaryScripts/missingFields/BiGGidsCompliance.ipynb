{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curation of BiGG ids\n",
    "\n",
    "Notebook for correcting misc. issues with BiGG dictionaries provided by @snmendoz in PR #188.\n",
    "\n",
    "## 1. Splitting list into separate lists\n",
    "\n",
    "We will start by splitting the original met/reaction files into 2 separates based on if they belong or not to BiGG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for splitting the file in two:\n",
    "import csv\n",
    "import os\n",
    "def split_in_two(old_file_name, bigg_file_name):\n",
    "    # Create list with BiGG ids:\n",
    "    with open(bigg_file_name) as bigg_file:\n",
    "        bigg_list = bigg_file.read().splitlines()\n",
    "        \n",
    "        \n",
    "    # Split file in two:\n",
    "    in_file_name = old_file_name.replace(\".csv\",\"_in.csv\")\n",
    "    out_file_name = old_file_name.replace(\".csv\",\"_newIDs.csv\")\n",
    "    with open(old_file_name) as old_file:\n",
    "        with open(in_file_name, 'w', newline='') as in_file:\n",
    "            with open(out_file_name, 'w', newline='') as out_file:\n",
    "                old_reader = csv.reader(old_file, delimiter=',')\n",
    "                in_writer = csv.writer(in_file, delimiter=',')\n",
    "                out_writer = csv.writer(out_file, delimiter=',')\n",
    "                for row in old_reader:\n",
    "                    if row[1] in bigg_list:\n",
    "                        in_writer.writerow([row[0], row[1]])\n",
    "                    else:\n",
    "                        out_writer.writerow([row[0], row[1]])\n",
    "\n",
    "    # Replace file:\n",
    "    os.remove(old_file_name)\n",
    "    os.rename(in_file_name, old_file_name)\n",
    "\n",
    "# Split both metabolite and reaction files:\n",
    "split_in_two('../../ComplementaryData/databases/BiGGmetDictionary.csv', '../../ComplementaryData/databases/mets_already_in_bigg.txt')\n",
    "split_in_two('../../ComplementaryData/databases/BiGGrxnDictionary.csv', '../../ComplementaryData/databases/rxns_already_in_bigg.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Removing compartment info in met ids\n",
    "\n",
    "BiGG ids for metabolites don't include any compartment info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for removing compartment info:\n",
    "import csv\n",
    "import os\n",
    "def remove_comp_info(file_name):\n",
    "    new_file_name = file_name.replace(\".csv\",\"_new.csv\")\n",
    "    with open(file_name) as old_file:\n",
    "        with open(new_file_name, 'w', newline='') as new_file:\n",
    "            bigg_reader = csv.reader(old_file, delimiter=',')\n",
    "            bigg_writer = csv.writer(new_file, delimiter=',')\n",
    "            for row in bigg_reader:\n",
    "                if len(row[1].split(\"[\")) == 2:\n",
    "                    bigg_writer.writerow([row[0], row[1].split(\"[\")[0]])\n",
    "                else:\n",
    "                    print(\"Warning: \" + row[1])\n",
    "\n",
    "    # Replace file:\n",
    "    os.remove(file_name)\n",
    "    os.rename(new_file_name, file_name)\n",
    "\n",
    "#Remove compartment from both BiGG met files:\n",
    "remove_comp_info('../../ComplementaryData/databases/BiGGmetDictionary.csv')\n",
    "remove_comp_info('../../ComplementaryData/databases/BiGGmetDictionary_newIds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lipid ids\n",
    "\n",
    "We'll redefine these ids to be more systematic with the traditional way of annotating lipids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1-monoglyceride': 'mag', 'diglyceride': 'dag', '1,2-diacylglycerol 3-diphosphate': 'dag2p', 'CDP-diacylglycerol': 'cdpdag', 'triglyceride': 'tag', 'phosphatidate': 'pa', 'phosphatidyl-L-serine': 'ps', '1-acylglycerophosphoserine': 'agps', 'phosphatidylethanolamine': 'pe', 'phosphatidyl-N-methylethanolamine': 'mmpe', 'phosphatidyl-N,N-dimethylethanolamine': 'dmpe', '1-acylglycerophosphoethanolamine': 'agpe', 'phosphatidylcholine': 'pc', '1-acylglycerophosphocholine': 'agpc', 'long-chain base': 'lcb', '1-phosphatidyl-1D-myo-inositol': 'pail', 'sn-2-acyl-1-lysophosphatidylinositol': 'lpi', 'ceramide': 'cer', 'inositol-P-ceramide': 'ipc', 'mannosylinositol phosphorylceramide': 'mipc', 'inositol phosphomannosylinositol phosphoceramide': 'mip2c', '3-(3-sn-phosphatidyl)-sn-glycerol 1-phosphate': 'pg1p', 'acylglycerone phosphate': 'agp', 'phosphatidylglycerol': 'pg', 'cardiolipin': 'cl', 'monolysocardiolipin': 'mlcl'}\n"
     ]
    }
   ],
   "source": [
    "# Load dictionary with traditional abbreviations:\n",
    "import csv\n",
    "lip_id_dict = {}\n",
    "with open('../../ComplementaryData/databases/lipidAbbreviations.csv') as lip_id_file:\n",
    "    lip_id_reader = csv.reader(lip_id_file, delimiter=';')\n",
    "    for row in lip_id_reader:\n",
    "        lip_id_dict[row[1]] = row[0]\n",
    "print(lip_id_dict)\n",
    "\n",
    "# Create new BiGG ids compliant with lipid standards:\n",
    "import cobra\n",
    "model = cobra.io.read_sbml_model(\"../../ModelFiles/xml/yeastGEM.xml\")\n",
    "file_name = '../../ComplementaryData/databases/BiGGmetDictionary_newIDs.csv'\n",
    "new_file_name = file_name.replace(\".csv\",\"_new.csv\")\n",
    "with open(file_name) as old_file:\n",
    "    with open(new_file_name, 'w', newline='') as new_file:\n",
    "        bigg_reader = csv.reader(old_file, delimiter=',')\n",
    "        bigg_writer = csv.writer(new_file, delimiter=',')\n",
    "        for row in bigg_reader:\n",
    "            met = model.metabolites.get_by_id(row[0])\n",
    "            new_met_id = row[1]\n",
    "            for key, proper_id in lip_id_dict.items():\n",
    "                if met.name.startswith(key):\n",
    "                    new_met_id = met.name.split(\"[\")[0]  # remove compartment info\n",
    "                    new_met_id = new_met_id.replace(key, proper_id)  # replace name with compliant id\n",
    "                    new_met_id = new_met_id.replace(\"backbone\", \"\")  # remove \"backbone\" in generic species\n",
    "                    new_met_id = new_met_id.replace(\"-bisphosphate\", \"bp\")  # for pail species\n",
    "                    new_met_id = new_met_id.replace(\"-phosphate\", \"p\")  # for pail species\n",
    "                    new_met_id = new_met_id.replace(\"phosphate\", \"p\")  # for lcb species\n",
    "                    if proper_id in [\"cer\", \"ipc\", \"mipc\", \"mip2c\"]:  # sphingolipids\n",
    "                        new_met_id = new_met_id.replace(\"'\", \"a\")  # \"a\" stands for \"apostrophe\"\n",
    "                        new_met_id = new_met_id.replace(\"(C\", \"\")  # redundant info\n",
    "                        for index, let in enumerate(\"ABCD\"):\n",
    "                            new_met_id = new_met_id.replace(let, str(index+1))  # use the same standard for all\n",
    "                    for num in \"1234\":\n",
    "                        new_met_id = new_met_id.replace(num + \"-\", \"\")  # the order of chains is implied from the string\n",
    "                    for bad_char in \" ():,-\":\n",
    "                        new_met_id = new_met_id.replace(bad_char, \"\")  # to stay BiGG compliant\n",
    "                    break\n",
    "            bigg_writer.writerow([row[0], new_met_id])\n",
    "\n",
    "# Rename file:\n",
    "import os\n",
    "os.remove(file_name)\n",
    "os.rename(new_file_name, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SLIME rxn ids\n",
    "\n",
    "To be consistent with the newly defined lipid ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary with ALL BiGG met ids:\n",
    "import csv\n",
    "def add_to_bigg_dict(file_name, met_bigg_dict):\n",
    "    with open(file_name) as met_file:\n",
    "        met_reader = csv.reader(met_file, delimiter=',')\n",
    "        for row in met_reader:\n",
    "            met_bigg_dict[row[0]] = row[1]\n",
    "    return met_bigg_dict\n",
    "met_bigg_dict = add_to_bigg_dict('../../ComplementaryData/databases/BiGGmetDictionary.csv', {})\n",
    "met_bigg_dict = add_to_bigg_dict('../../ComplementaryData/databases/BiGGmetDictionary_newIDs.csv', met_bigg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new BiGG ids for SLIME rxns compliant with lipid standards:\n",
    "import cobra\n",
    "model = cobra.io.read_sbml_model(\"../../ModelFiles/xml/yeastGEM.xml\")\n",
    "file_name = '../../ComplementaryData/databases/BiGGrxnDictionary_newIDs.csv'\n",
    "new_file_name = file_name.replace(\".csv\",\"_new.csv\")\n",
    "with open(file_name) as old_file:\n",
    "    with open(new_file_name, 'w', newline='') as new_file:\n",
    "        bigg_reader = csv.reader(old_file, delimiter=',')\n",
    "        bigg_writer = csv.writer(new_file, delimiter=',')\n",
    "        for row in bigg_reader:\n",
    "            try:\n",
    "                rxn = model.reactions.get_by_id(row[0])\n",
    "                new_rxn_id = row[1]\n",
    "                if rxn.name.endswith(\"SLIME rxn\"):\n",
    "                    met = rxn.reactants[0]\n",
    "                    new_rxn_id = f\"{met_bigg_dict[met.id]}SLIME{met.compartment}\"\n",
    "                bigg_writer.writerow([row[0], new_rxn_id])\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "# Rename file:\n",
    "import os\n",
    "os.remove(file_name)\n",
    "os.rename(new_file_name, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exchange rxns\n",
    "\n",
    "The standard in BiGG is `EX_id_e`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new BiGG ids for exchange rxns:\n",
    "import cobra\n",
    "model = cobra.io.read_sbml_model(\"../../ModelFiles/xml/yeastGEM.xml\")\n",
    "file_name = '../../ComplementaryData/databases/BiGGrxnDictionary_newIDs.csv'\n",
    "new_file_name = file_name.replace(\".csv\",\"_new.csv\")\n",
    "with open(file_name) as old_file:\n",
    "    with open(new_file_name, 'w', newline='') as new_file:\n",
    "        bigg_reader = csv.reader(old_file, delimiter=',')\n",
    "        bigg_writer = csv.writer(new_file, delimiter=',')\n",
    "        for row in bigg_reader:\n",
    "            try:\n",
    "                rxn = model.reactions.get_by_id(row[0])\n",
    "                new_rxn_id = row[1]\n",
    "                if len(rxn.metabolites) == 1:\n",
    "                    met = list(rxn.metabolites)[0]\n",
    "                    if met.compartment == 'e':\n",
    "                        new_rxn_id = f\"EX_{met_bigg_dict[met.id]}_{met.compartment}\"\n",
    "                bigg_writer.writerow([row[0], new_rxn_id])\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "# Rename file:\n",
    "import os\n",
    "os.remove(file_name)\n",
    "os.rename(new_file_name, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transport rxns\n",
    "\n",
    "For all transports of the type `met_a -> met_b` We will use as standard `METtab`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranlsator for compartments:\n",
    "def translate_compartment(compartment):\n",
    "    if compartment == \"p\":\n",
    "        compartment = \"x\"\n",
    "    elif compartment == \"er\":\n",
    "        compartment = \"r\"\n",
    "    elif compartment == \"erm\":\n",
    "        compartment = \"rm\"\n",
    "    elif compartment in [\"c\",\"e\"]:\n",
    "        compartment = \"\"  # cytosol/extracellular are typically not indicated in the BiGG id\n",
    "    return compartment\n",
    "\n",
    "# Create new BiGG ids for exchange rxns:\n",
    "import cobra\n",
    "model = cobra.io.read_sbml_model(\"../../ModelFiles/xml/yeastGEM.xml\")\n",
    "file_name = '../../ComplementaryData/databases/BiGGrxnDictionary_newIDs.csv'\n",
    "new_file_name = file_name.replace(\".csv\",\"_new.csv\")\n",
    "with open(file_name) as old_file:\n",
    "    with open(new_file_name, 'w', newline='') as new_file:\n",
    "        bigg_reader = csv.reader(old_file, delimiter=',')\n",
    "        bigg_writer = csv.writer(new_file, delimiter=',')\n",
    "        for row in bigg_reader:\n",
    "            try:\n",
    "                rxn = model.reactions.get_by_id(row[0])\n",
    "                new_rxn_id = row[1]\n",
    "                if len(rxn.metabolites) == 2:\n",
    "                    sub = list(rxn.reactants)[0]\n",
    "                    pro = list(rxn.products)[0]\n",
    "                    sub_id = met_bigg_dict[sub.id]\n",
    "                    pro_id = met_bigg_dict[pro.id]\n",
    "                    if sub_id == pro_id:\n",
    "                        sub_c = translate_compartment(sub.compartment)\n",
    "                        pro_c = translate_compartment(pro.compartment)\n",
    "                        new_rxn_id = f\"{sub_id.upper()}t{sub_c}{pro_c}\"\n",
    "                bigg_writer.writerow([row[0], new_rxn_id])\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "# Rename file:\n",
    "import os\n",
    "os.remove(file_name)\n",
    "os.rename(new_file_name, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Lipid rxn ids\n",
    "\n",
    "The position of the chain is redundant information, e.g. `KIN11812181gm` can just be `KIN181181gm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new BiGG ids compliant with lipid standards:\n",
    "import cobra\n",
    "import csv\n",
    "from copy import copy\n",
    "from re import findall\n",
    "model = cobra.io.read_sbml_model(\"../../ModelFiles/xml/yeastGEM.xml\")\n",
    "file_name = '../../ComplementaryData/databases/BiGGrxnDictionary_newIDs.csv'\n",
    "new_file_name = file_name.replace(\".csv\",\"_new.csv\")\n",
    "with open(file_name) as old_file:\n",
    "    with open(new_file_name, 'w', newline='') as new_file:\n",
    "        bigg_reader = csv.reader(old_file, delimiter=',')\n",
    "        bigg_writer = csv.writer(new_file, delimiter=',')\n",
    "        for row in bigg_reader:\n",
    "            rxn = model.reactions.get_by_id(row[0])\n",
    "            new_rxn_id = row[1]\n",
    "            chains = findall('\\(.*?\\)',rxn.name)\n",
    "            if len(chains) > 0:\n",
    "                bad_number = \"\"\n",
    "                good_number = \"\"\n",
    "                for chain in chains:\n",
    "                    good_chain = copy(chain)\n",
    "                    for num in \"1234\":\n",
    "                        good_chain = good_chain.replace(num + \"-\", \"\")  # the order of chains is implied from the string\n",
    "                    for bad_char in \" ():,-\":\n",
    "                        chain = chain.replace(bad_char, \"\")  # to stay BiGG compliant\n",
    "                        good_chain = good_chain.replace(bad_char, \"\")  # to stay BiGG compliant\n",
    "                    bad_number = bad_number + chain\n",
    "                    good_number = good_number + good_chain\n",
    "                new_rxn_id = new_rxn_id.replace(bad_number, good_number)\n",
    "            bigg_writer.writerow([row[0], new_rxn_id])\n",
    "\n",
    "# Rename file:\n",
    "import os\n",
    "os.remove(file_name)\n",
    "os.rename(new_file_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
